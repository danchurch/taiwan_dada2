## scratch work for the dada2 notebook 


######################################################

## removing primers from wood reads? Or are they already gone?

## unzip wood reads
for i in *
do 
gunzip $i
done

## look:
head lane1-s160-index-AAGCACTG-GTGATCCANNNN-Dc-X_S160_L001_R1_001.fastq

## general ITS1f:
grep CTTGGTCATTTAGAGGAAGTAA lane1-s160-index-AAGCACTG-GTGATCCANNNN-Dc-X_S160_L001_R1_001.fastq

grep CTTGGTCATTTAGAGGAAGTAA lane1-s160-index-AAGCACTG-GTGATCCANNNN-Dc-X_S160_L001_R2_001.fastq
## nope

## all files:
grep CTTGGTCATTTAGAGGAAGTAA -R ./ | wc -l  ## 129 

grep ^CTTGGTCATTTAGAGGAAGTAA -R ./  ## just one?
grep ^CTTGGTCATTTAGAGGAAGTAA -R ./ | wc -l  ## yup

## reverse compliment of ITS1f?
grep CTTCCTCTAAATGACCAAG -R ./  ## all R2, by the looks

grep CTTCCTCTAAATGACCAAG -R ./ > wtf.txt &  

grep CTTCCTCTAAATGACCAAG -R ./ | wc -l ## 2,370,829 eh? 

grep ^CTTCCTCTAAATGACCAAG -R ./ | wc -l

## how many reads do I have in total?
grep ^@M0 -R ./ | wc -l ## 11135598, /2 = ~5.56 x 10^6
## so I guess nearly half of these reads have the reverse compliment on them, near the end of their sequence. 

## should I get rid of this? Seems like best to clip it off...




## general ITS2:
grep GCTGCGTTCTTCATCGATGC lane1-s160-index-AAGCACTG-GTGATCCANNNN-Dc-X_S160_L001_R1_001.fastq
grep GCTGCGTTCTTCATCGATGC lane1-s160-index-AAGCACTG-GTGATCCANNNN-Dc-X_S160_L001_R2_001.fastq
## nope

## all files:
grep GCTGCGTTCTTCATCGATGC -R ./ | wc -l  ## 57, R1 and R2

grep ^GCTGCGTTCTTCATCGATGC -R ./  ##
grep ^GCTGCGTTCTTCATCGATGC -R ./ | wc -l  ##


## get back to these, will remove the floating primer reads later

## reverse compliment of ITS2?
grep GCATCGATGAAGAACGCAGC -R ./ 

grep ^GCATCGATGAAGAACGCAGC -R ./  | wc -l ## 213 weird, some amount of these start with ITS 2, reverse compliment

grep GCATCGATGAAGAACGCAGC -R ./ | wc -l  ## 2,802,824. As above 

grep GCATCGATGAAGAACGCAGC -R ./ > wtf2.txt &

grep R1 wtf2.txt | wc -l ## 2803811 around half, again

grep R2 wtf2.txt | wc -l ## 13. A few.


## so I think the story here is that the R1 are my forward reads.
## They contain the reverse compliment of the other primer, near
## their ends.

## The same is true for the R2, which must be my reverse reads

## so plan to clean up:

## 1) clip off the ends, reverse primer on. 
## 2) remove any remaining reads with either primer
## or the RC of either primer anywhere in the 
## in the sequence.  
## 3) also remove the matched read from the other 
## other direction 

## but first, let's get Roo's demultiplexed, and see if there 
## are similar issues ....

################################################

## demult Roo's reads

## can we use the fastx barcode splitter to demultiplex?
## I remember he used split barcodes, golay...

## what do his reads look like?

cd /home/daniel/Documents/taiwan/leafreads

head -n 8 TaiwanFA_R2.fastq

## what are we looking at here? 

ITS1f=CTTGGTCATTTAGAGGAAGTAA

head -n 8 TaiwanFA_R2.fastq | grep $ITS1f ## lotsa floating primers but no anchored primer. Golays must go first
## 159 floaters
## 18 million reads total?

grep $ITS1f TaiwanFA_R1.fastq | wc -l && wc -l TaiwanFA_R1.fastq

## half of one set of barcodes

## so for instance, our first barcode is:
## ACCCATATATCC
## the first half of this should be abundant as the first six BP of many of the reads:

head -n 1000000 TaiwanFA_R2.fastq | grep ^ACCCAT 

head -n 1000000 TaiwanFA_R2.fastq | grep ^ACCCAT | wc -l ## 12,267 reads
## yeah, that works. 

## the other half should be abundant as the start of many of the R1 reads:

head -n 1000000 TaiwanFA_R1.fastq | grep ^ATATCC
head -n 1000000 TaiwanFA_R1.fastq | grep ^ATATCC | wc -l ## 13,156 reads

## how do we know we have the same read order for forward and reverse?

head -n 4 TaiwanFA_R1.fastq
head -n 4 TaiwanFA_R2.fastq

head -n 24 TaiwanFA_R1.fastq | sed -n '1~4p' 
head -n 24 TaiwanFA_R2.fastq | sed -n '1~4p' 

tail -n 24 TaiwanFA_R1.fastq | sed -n '1~4p' 
tail -n 24 TaiwanFA_R2.fastq | sed -n '1~4p' 

## they seem to be ordered correctly. 

## let's try my old script:

cd /home/daniel/Documents/taiwan/taiwan_dada2
wget https://raw.githubusercontent.com/danchurch/taiwan_combined_biom/master/scripts/BCunsplit4.py
mv BCunsplit4.py BCunsplit.py
chmod 775 BCunsplit.py

## make toy files:
head -n 1000 ../leafreads/TaiwanFA_R1.fastq > toy_R1.fastq
head toy_R1.fastq

head -n 1000 ../leafreads/TaiwanFA_R2.fastq > toy_R2.fastq
head toy_R2.fastq

## I think that the old script removed the primers entirely from
## the reverse reads, and relied on the exact matching of order
## to keep things organized. But I think here we need both the 
## reverse and forward reads to keep a copy of their barcodes, 
## since demultiplexing occurs prior to merging, using these
## barcodes.

## so edits made. Try it out:

./BCunsplit.py toy_R2.fastq toy_R1.fastq

## look at the results:

## take the first six BP of the first 10 reads from each, 
## check to see if they are the same
aa=$(head -n 40 rearranged_toy_R2.fastq | sed -n '2~4p' | cut -c -6)
bb=$(head -n 40 toy_R2.fastq | sed -n '2~4p' | cut -c -6)
echo $aa
echo $bb
if [ "$aa" == "$bb" ]; then echo "true"; fi

## and the original?

cc=$(head -n 40 ../leafreads/TaiwanFA_R2.fastq | sed -n '2~4p' | cut -c -6)
echo $aa
echo $cc
if [ "$aa" == "$cc" ]; then echo "true"; fi

## all the way?:

aa=$(tail -n 40 rearranged_toy_R2.fastq | sed -n '2~4p' | cut -c -6)
bb=$(tail -n 40 toy_R2.fastq | sed -n '2~4p' | cut -c -6)
echo $aa
echo $bb
if [ "$aa" == "$bb" ]; then echo "true"; fi

## looks good

## now barcodes of the forward and reverse rearranged files should match, too:
aa=$(head -n 40 rearranged_toy_R1.fastq | sed -n '2~4p' | cut -c -12)
bb=$(head -n 40 rearranged_toy_R2.fastq | sed -n '2~4p' | cut -c -12)
echo $aa
echo $bb
if [ "$aa" == "$bb" ]; then echo "true"; fi

aa=$(tail -n 40 rearranged_toy_R1.fastq | sed -n '2~4p' | cut -c -12)
bb=$(tail -n 40 rearranged_toy_R2.fastq | sed -n '2~4p' | cut -c -12)
echo $aa
echo $bb
if [ "$aa" == "$bb" ]; then echo "true"; fi

## looks good to me

## let's do it on the whole data set:

time ./BCunsplit.py ../leafreads/TaiwanFA_R2.fastq ../leafreads/TaiwanFA_R1.fastq

## okay, way too big for my little script - not sure why. I thought 
## using the iterators in python kept the memory use down, even with
## large files

## so either I tinker more with the script or I break up the file 
## into a smaller size. 

## since I don't know how to scale up the script right now, let's try 
## breaking up the file

## how?

## how many lines in Roo's reads? 

leafR1=/home/daniel/Documents/taiwan/leafreads/TaiwanFA_R1.fastq
leafR2=/home/daniel/Documents/taiwan/leafreads/TaiwanFA_R2.fastq

wc -l $leafR1 && wc -l $leafR2

## 73 x 10^6 lines. As long as we split by multiples of four, we should
## be able to maintain our read order. Try files of 10 x 10^6 reads

split -d -l 10000000 $leafR1 leafR1sub

split -d -l 10000000 $leafR2 leafR2sub

## scoured the files with head/tail, they seem to have preserved order
## and kept the individual reads with their quality scores and headers
## intact. 

## so now what? run our barcode rearrangement script on them, concatenate.

## what does this look like?

time ../BCunsplit.py leafR2sub00 leafR1sub00

## yeah works. So let's try:

nus=(00 01 02 03 04 05 06 07)
for i in ${nus[*]}
do 
../BCunsplit.py leafR2sub$i leafR1sub$i
done

## now concatenate:
ls leafR1sub0*

ls leafR2sub0*

cat rearranged_leafR1sub0* > rearranged_leafR1.fastq && cat rearranged_leafR2sub0* > rearranged_leafR2.fastq &

## did this work? line order maintained? Random line checks

grep ACCCATATATCC rearranged_leafR1.fastq | wc -l ## 15
grep ACCCATATATCC $leafR1 | wc -l ## 15

head -n 4 $leafR1

## huh, not seeing the barcode. 

## do the forward and reverse rearranged barcodes match, at least? 
aa=$(head -n 40 rearranged_leafR1.fastq | sed -n '2~4p' | cut -c -12)
bb=$(head -n 40 rearranged_leafR2.fastq | sed -n '2~4p' | cut -c -12)

echo $aa
echo $bb
if [ "$aa" == "$bb" ]; then echo "true"; fi

## yeah, but these aren't barcodes. 
## where are the barcodes?
## and where are the primers? Am I going crazy here?

ITS1f=CTTGGTCATTTAGAGGAAGTAA
ITS1fRC=TTACTTCCTCTAAATGACCAAG
ITS2=GCTGCGTTCTTCATCGATGC
ITS2RC=GCATCGATGAAGAACGCAGC

head $leafR2 | grep G

head $leafR2 | grep $ITS1f
head $leafR2 | grep $ITS1fRC
head $leafR2 | grep $ITS2
head $leafR2 | grep $ITS2RC

head -n 4000 $leafR2 | grep $ITS1f
head -n 4000 $leafR2 | grep $ITS1fRC
head -n 4000 $leafR2 | grep $ITS2
head -n 4000 $leafR2 | grep $ITS2RC

head -n 4000 $leafR2 | grep ${ITS1f::5} | wc -l 

## nearly all, first five of primer (905 out of 1000 reads)
## the first six must be the first half of the BC
## primer sequences must be in bad shape

head -n 4000 $leafR2 | grep ^${ITS1f::5} | wc -l ## only 1. So these are not starting with ITS1f, BC first

head -n 4000 $leafR2 | grep ${ITS1f::5}  ## generally after 6 bp, makes sense

## how about with the rearranged reads:

echo $(head -n 4000 rearranged_leafR2.fastq | grep ${ITS1f::5} | wc -l) &

echo $(grep ${ITS1f::5} rearranged_leafR2.fastq | wc -l) &

## ok, 12 bp, so that worked...
## but are these actually barcodes?

## check one barcode:
grep GGGCGCGGGGCG $leafR2 | wc -l ## 1105 - 1000 reads, possible, but that's not many...

## how many are where they are supposed to be?
aa=$(grep ^GGGCGCGGGGCG $leafR2 | wc -l) && echo $aa &
## 5. Just five. What the hell.

## check another:
grep ATCAAAAAGACG $leafR2 | wc -l ## 41 ????

aa=$(grep ^ATCAAAAAGACG $leafR2 | wc -l) && echo $aa & ## 0

## hmm, not understanding this...

## are these not the barcodes?

## shall we try demultiplexing with fastx and see what happens?

## first have to make the text file for fastx...

## should be as simple as listing the barcodes from Roo's map,
## with a name in front of each:

head leafread_map.txt

libreoffice --calc leafread_map.txt &

## okay, there's a bunch of carriage returns in Roo's text file,

## can we turn these into unix line breaks?

head -c 500 leafread_map.txt 

## let's try with dos2unix:

dos2unix -c mac -n leafread_map.txt leafread_map2.txt

## now get first two columns

head leafread_map2.txt | cut -f 1-2

cut -f 1-2 leafread_map2.txt > leafread_fastx_map.txt

## now will fastx split up our samples?

mkdir demult 
cd demult 

cat $leafR1 | fastx_barcode_splitter.pl --bcfile ../leafread_fastx_map.txt --prefix leaf_sample_  \
--bol --mismatches 1 --partial 1 

cat $leafR2 | fastx_barcode_splitter.pl --bcfile ../leafread_fastx_map.txt --prefix leaf_sample_  \
--bol --mismatches 1 --partial 1 

## it says labels must be alphanumeric...
## sed this problem?:

sed -i 's/\.1/A/' leafread_fastx_map.txt && sed -i 's/\.2/B/' leafread_fastx_map.txt

## try again...

cat ../rearranged_leafR1.fastq | fastx_barcode_splitter.pl --bcfile ../leafread_fastx_map.txt --prefix leafR1_  \
--bol --mismatches 1 --partial 1  &


cat ../../rearranged_leafR2.fastq | fastx_barcode_splitter.pl --bcfile ../../leafread_fastx_map.txt --prefix leafR2_  \
--bol --mismatches 1 --partial 1  &

## 4,042,017 reads unmatched.  Out of 18,201,615. 
## fair amount not matching, but I guess that's okay, 

##### removing primers ########

## two kinds of primers - traditional, beginning of line primers and
## floating primers, which I made a script for removing... we should look at it:

wget https://raw.githubusercontent.com/danchurch/taiwan_combined_biom/master/scripts/floatingprimers.py

## make sense, still. But to use it, we have to use a FASTA, not a fastq. Modify it?

## or maybe take a different approach. how about grepping the primer sequences and
## deleting the line if it has the sequence? and the previous and following lines?

cat > moop.txt

moop doldhjhlkhj
zoop lkjqewsbf
juzz xoop lakjdhur
toop caihgreiskhi
alwruhgieugh woop slkjfh


sed -n '/zoop/p' moop.txt

cat moop.txt

sed -i '/zoop/d' moop.txt

sed '/^zoop/,+2 d' moop.txt



head -n 8 leafR1_1 | sed '/TTTCTTTTACT/,+3 d' 
## but what about previous line?

## not so simple. what about grep?

head -n 8 leafR1_1 | grep 'TTTCTTTTACT' -A 2 -B 1

## to get line number
head -n 8 leafR1_1 | grep 'TTTCTTTTACT' -n | cut -d : -f 1

aa=$(grep 'TTTCTTTTACT' -m 1 -n leafR1_1 | cut -d : -f 1)
first=$(expr $aa - 1)
last=$(expr $aa + 2)

head -n 8 leafR1_1 | sed -n '5,8p'

head -n 8 leafR1_1 | sed '5,8d'

## but there will be many grep hits in a file, not just one...

ITS1f=CTTGGTCATTTAGAGGAAGTAA
ITS1fRC=TTACTTCCTCTAAATGACCAAG
ITS2=GCTGCGTTCTTCATCGATGC
ITS2RC=GCATCGATGAAGAACGCAGC

cp leafR1_1 test1

bb=$(grep -n $ITS1fRC test1 | cut -d : -f 1)

cc=($bb)

for i in $bb
do 

first=$(expr $i - 1)
last=$(expr $i + 2)
sed -i "$first,$last d" test1
echo $i done!
done

grep -n $ITS1fRC test1 | cut -d : -f 1

#### meh. what about finding the header address with grep, then 
## deleting with SED?

bb=$(grep -n -m 1 $ITS1fRC test1 | cut -d : -f 1)
cc=$(expr $bb - 1)
sed -n "$cc p" test1 ## okay works

############ 

## start over. We want to do three things:
## 1) remove revercompliment primers and everything 
##    after on all sequences that have them
## 2) remove floating primers
## 3) remove beginning of line primers and barcodes

## for #1, a simple sed sub command should do:

head -n 30 test1 > test2

grep $ITS1fRC test2

sed "s/$ITS1fRC.*//g" test2 > test3

ITS1f=CTTGGTCATTTAGAGGAAGTAA
ITS1fRC=TTACTTCCTCTAAATGACCAAG
ITS2=GCTGCGTTCTTCATCGATGC
ITS2RC=GCATCGATGAAGAACGCAGC

head -n 1000 rearranged_leafR2.fastq > toy_R2.fastq

grep -n $ITS2RC toy_R2.fastq | wc -l

grep -n $ITS2RC toy_R2.fastq

sed "s/$ITS2RC.*$//" toy_R2.fastq > toy_R2.1.fastq
sed -n "582p" toy_R2.fastq | grep $ITS2RC
sed -n "582p" toy_R2.1.fastq 

sed -n "582p" toy_R2.1.fastq | grep $ITS2RC


sed -n "790,792p" toy_R2.fastq  | grep $ITS2RC
sed -n "790,792p" toy_R2.1.fastq 

## R1, should have  RC of ITS2 in them:

head -n 1000 rearranged_leafR1.fastq > toy_R1.fastq

grep $ITS1fRC toy_R1.fastq 

grep $ITS1fRC toy_R1.fastq | wc -l ## 28 out of 250, ~10%!

grep $ITS1fRC rearranged_leafR1.fastq | wc -l ## 6,514,098, quite a lot. 

sed "s/$ITS1fRC.*$//" rearranged_leafR1.fastq > rearranged_leafR1.1.fastq

## R2, should have RC of ITS2 in them:

sed "s/$ITS2RC.*$//" rearranged_leafR2.fastq > rearranged_leafR2.1.fastq

## after doing this, many of these are very short:
zz=CGTTAACATACCCTTGGTNATTTAGAGGAAGTAAATGTTGCACTTTATTCAAAACAAAAGTACAAATATGCAAAGCCGAGATAAATACAACGGAGGATGAATCTACTCCAGACTTGTG
echo ${#zz} ## 118 BP

## so they may just be mutant reads we're going to have to throw out.

########################

## removing BOL barcodes and primers (and linkers?)

## should be simple: first 12 BP are barcodes. Then the ITS1f or ITS2. 

## But are the linker sequences in there somewhere? Don't think so,
## but let's make sure:

linker=GCTGCGTTCTTCATCGATGC
linkerRC=GCATCGATGAAGAACGCAGC

grep $linkerRC rearranged_leafR2.fastq | wc -l & ## huh...

grep $linkerRC <(head -n 10000 rearranged_leafR2.fastq) | wc -l ## 92

grep $linkerRC <(head -n 10000 rearranged_leafR2.fastq)  ## a fair amount...

grep $linkerRC <(head -n 10000 rearranged_leafR2.1.fastq) | wc  ## ...0...

grep $linkerRC <(head -n 10000 rearranged_leafR2.1.fastq)  ## so after the RC primers

grep $linker <(head -n 10000 rearranged_leafR2.fastq) | wc -l ## 0

## so it looks like they are mostly at the R1 side

grep $linker <(head -n 10000 rearranged_leafR1.fastq) | wc -l ## 2133

grep $linker <(head -n 10000 rearranged_leafR1.1.fastq) | wc -l ## 2133 

grep $linkerRC <(head -n 10000 rearranged_leafR1.fastq) | wc -l ## 0

## so it looks like the linker function remains in the R1 reads, 
## but not the R2?

## perhaps this is the definition of R1 - the set of reads that 
## had the linker sequence. Dunno. 

## anyway, so where are the primer sequences?

ITS1f=CTTGGTCATTTAGAGGAAGTAA
ITS1fRC=TTACTTCCTCTAAATGACCAAG
ITS2=GCTGCGTTCTTCATCGATGC
ITS2RC=GCATCGATGAAGAACGCAGC


echo ${#linker} ## linker is 20 bp

echo ${#ITS1f} #ITS1f is 22 bp

echo ${#ITS2} ## ITS2 is 20 bp

## so theoretically, the primers on the 
## R1 reads should start at 12+20+1 = bp33
## and go for 20 bp, so bp52

## R2 reads should start right after 
## barcodes, so 12+1 = bp13, and go 
## for 22 bp, till bp24

## is this true?

## we know the primer regions are really degenerate
## in these early reads...

grep $ITS1f <(head -n 10000 rearranged_leafR2.1.fastq) 

grep CTTGGTCATTTAGAGGAAGTAA <(head -n 10000 rearranged_leafR2.1.fastq) 

## CTTGGTCATTTAGAGGAAGTAA ##actual ITS1f
## CTTGGTNCTTTCTATGCACTAA ##from first read
## CTTGGT..TTT..A.G.A.TAA ## try searching with this

grep CTTGGT..TTT..A.G.A.TAA <(head -n 10000 rearranged_leafR2.1.fastq) | wc -l
## 1996, out of 2500

grep CTTGGT..TTT..A.G.A.TAA <(head -n 10000 rearranged_leafR2.1.fastq) 


##### ITS2 for R1 reads?

grep GCTGCGTTCTTCATCGATGC <(head -n 10000 rearranged_leafR1.1.fastq) | wc -l ##2133
## much higher quality than R2 primer region

## fastx trimmer for R1 reads:

## primer is ITS2 (20bp) + 12bp barcodes, so first bp to keep is
## 33

fastx_trimmer -i rearranged_leafR1.1.fastq -Q33 -f 33 -o rearranged_leafR1.2.fastq

## fastx trimmer for R2 reads:

## primer is ITS1f (22bp) + 12bp barcodes, so first bp to keep is
## 35


## not working. -q33 not helping. something's up... now that I think about it,
## I don't think I added the quality info back in for the reverse half of the 
## barcodes into the forward reads and vice versa...does this matter here?

## check this:

head -n 4 rearranged_leafR2.1.fastq 

expr length $(sed -n '2p' <(head -n 10 rearranged_leafR2.1.fastq))
expr length $(sed -n '4p' <(head -n 10 rearranged_leafR2.1.fastq))
## same

expr length $(sed -n '2p' <(head -n 10 rearranged_leafR1.1.fastq))
expr length $(sed -n '4p' <(head -n 10 rearranged_leafR1.1.fastq))
## not same. How to fix this? Have to go back into the script...

## but first, is the problem? Yeah, cuz this works:

fastx_trimmer -i -q33 rearranged_leafR2.1.fastq -f 35 -o rearranged_leafR2.2.fastq

## so it's the R1 reads needs be fixed...

## back up like two weeks, fix script...

## okay, did that work?


head -n 1000 ../leafreads/TaiwanFA_R1.fastq > toy_R1.fastq
head -n 1000 ../leafreads/TaiwanFA_R2.fastq > toy_R2.fastq

./BCunsplit.py toy_R2.fastq toy_R1.fastq

expr length $(sed -n '2p' <(head -n 10 rearranged_toy_R1.fastq))
expr length $(sed -n '4p' <(head -n 10 rearranged_toy_R1.fastq))

expr length $(sed -n '2p' <(head -n 10 rearranged_toy_R2.fastq))
expr length $(sed -n '4p' <(head -n 10 rearranged_toy_R2.fastq))

## seems like it works. okay, go back and repeat pipeline with 
## this script...

## make sure it worked

leafR1=/home/daniel/Documents/taiwan/leafreads/TaiwanFA_R1.fastq
leafR2=/home/daniel/Documents/taiwan/leafreads/TaiwanFA_R2.fastq

## do headers match everywhere?

sed -n '1p' <(head $leafR1)
sed -n '1p' <(head rearranged_leafR1.fastq)
sed -n '1p' <(head $leafR2)
sed -n '1p' <(head rearranged_leafR2.fastq)

sed -n '1p' <(tail -n 4 $leafR1)
sed -n '1p' <(tail -n 4 rearranged_leafR1.fastq)
sed -n '1p' <(tail -n 4 $leafR2)
sed -n '1p' <(tail -n 4 rearranged_leafR2.fastq)


expr length $(sed -n '2p' <(head rearranged_leafR2.fastq))
expr length $(sed -n '2p' <(head rearranged_leafR1.fastq))

expr length $(sed -n '12p' <(head -n 100 $leafR2))
expr length $(sed -n '12p' <(head -n 100 $leafR1))

sed -n '2~4p' <(head -n 100 rearranged_leafR2.fastq)

echo $(sed -n '2p' <(head -n 4 rearranged_leafR2.fastq))
echo $(sed -n '4p' <(head -n 4 rearranged_leafR2.fastq))
expr length $(sed -n '2p' <(head -n 4 rearranged_leafR2.fastq))
expr length $(sed -n '4p' <(head -n 4 rearranged_leafR2.fastq))

echo $(sed -n '2p' <(tail -n 4 rearranged_leafR2.fastq))
echo $(sed -n '4p' <(tail -n 4 rearranged_leafR2.fastq))
expr length $(sed -n '2p' <(tail -n 4 rearranged_leafR2.fastq))
expr length $(sed -n '4p' <(tail -n 4 rearranged_leafR2.fastq))

#####################3

## just realized all that work for cutting off
## primers was a little misdirected. It needs 
## to happen to the demultiplexed files, not
## the combination reads. 

## how to do this? Do it tomorrow, but 


## I think it would looks something like:


## for R1:

## first, remove RC primers and everything past
cd /home/daniel/Documents/taiwan/taiwan_dada2/leaf_demult_fastx/R1_demult

for i in * 
do
sed "s/$ITS1fRC.*$//" $i > $i.1.fastq
done

## then remove BOL barcodes/primer
for i in *
do
fastx_trimmer -i $i -f 33 -o $i.2.fastq
done

## do also for R2.

## then check read order

## then start the dada2 pipeline

## then repeat the analysis from the paper

## jeezus christ

###########

## check order after demultiplexing:

R1dmult=/home/daniel/Documents/taiwan/taiwan_dada2/leaf_demult_fastx/R1_demult
R2dmult=/home/daniel/Documents/taiwan/taiwan_dada2/leaf_demult_fastx/R2_demult

cd $R1dmult 

aa=$(head -n 1 $R1dmult/leafR1_1)
echo ${aa: -30: -7} 
aa=$(head -n 1 $R2dmult/leafR2_1)
echo ${aa: -30: -7} 


aa=$(sed -n "1~4p" <( head -n 100 $R1dmult/leafR1_1) | cut -d : -f 6,7 | cut -d ' ' -f 1)
bb=$(sed -n "1~4p" <( head -n 100 $R2dmult/leafR2_1) | cut -d : -f 6,7 | cut -d ' ' -f 1)
if [ "$aa" == "$bb" ]
then echo "same!"
else echo "different!"
fi

cp $R1dmult/leafR1_20 ./fakeR1_20

sed -n '1p' fakeR1_20

sed -i '1s/18044:1415/18044:1416/' fakeR1_20

aa=$(sed -n "1~4p" <( head -n 10000 $R1dmult/leafR1_20) | cut -d : -f 6,7 | cut -d ' ' -f 1)
bb=$(sed -n "1~4p" <( head -n 10000 $R2dmult/fakeR1_20) | cut -d : -f 6,7 | cut -d ' ' -f 1)
if [ "$aa" == "$bb" ]
then echo "same!"
else echo "different!"
fi


aa=$(sed -n "1~4p" <( head -n 100000 $R1dmult/leafR1_79) | cut -d : -f 6,7 | cut -d ' ' -f 1)
bb=$(sed -n "1~4p" <( head -n 100000 $R2dmult/leafR2_79) | cut -d : -f 6,7 | cut -d ' ' -f 1)
if [ "$aa" == "$bb" ]
then echo "same!"
else echo "different!"
fi

############

## how to cleanup runover primers and sequence from all the demultiplexed samples?

cd /home/daniel/Documents/taiwan/taiwan_dada2/leaf_demult_fastx/R1_demult

## R1 reads are reverse reads, they should start with ITS2 and 
## and end with RC of ITS1f. Check this:

ITS1f=CTTGGTCATTTAGAGGAAGTAA
degenITS1f=CTTGGT..TTT..A.G.A.TAA
ITS1fRC=TTACTTCCTCTAAATGACCAAG
ITS2=GCTGCGTTCTTCATCGATGC
ITS2RC=GCATCGATGAAGAACGCAGC

grep $degenITS1f <(head -n 1000 leafR1_97)

grep $ITS1fRC <(head -n 1000 leafR1_97)

grep $ITS2RC <(head -n 1000 leafR1_97) | wc -l ## 0

grep $ITS2RC <(head -n 1000 leafR2_97) | wc -l ## 14 out of 78,000 or so. 

grep $ITS1fRC <(head -n 1000 leafR1_97) | wc -l

cd /home/daniel/Documents/taiwan/taiwan_dada2/leaf_demult_fastx/R1_demult

for i in leafR1*
do 
sed "s/$ITS1fRC.*$//" $i > runover_removed/$i.1
echo $i.1
done 


cd /home/daniel/Documents/taiwan/taiwan_dada2/leaf_demult_fastx/R2_demult
for i in leafR2*
do 
sed "s/$ITS2RC.*$//" $i > runover_removed/$i.1
echo $i.1
done 

## but shit. how do we remove the accompanying qscore lengths?

## we now need to check each sequence, and make sure qscore and 
## sequence lengths match. Shit. 

## probably python time. 

## ok, prototype script ready. does it work?

./remove_runover.py -p $ITS2RC -f <(head -n 1000 rearranged_leafR2.fastq) -o ~/testwrite.fastq

## sanity checks:

grep $ITS2RC rearranged_leafR2.fastq | wc -l &

grep $ITS2RC <(head -n 1000 rearranged_leafR2.fastq) | wc -l

grep $ITS2RC <(head -n 1000 rearranged_leafR2.fastq) -n ## lines 582 and 790

## how do these look in our output?

grep $ITS2RC testwrite.fastq ## nada

sed -n '581,586p' <(head -n 1000 rearranged_leafR2.fastq) | grep $ITS2RC -A 2 -B 1
##############################
sed -n '581,586p' <(head -n 1000 rearranged_leafR2.fastq) 
##############################
sed -n '581,586p' testwrite.fastq

sed -n '789,794p' <(head -n 1000 rearranged_leafR2.fastq) | grep $ITS2RC -A 2 -B 1
##############################
sed -n '789,794p' <(head -n 1000 rearranged_leafR2.fastq) 
##############################
sed -n '789,794p' testwrite.fastq

## looks okay. Try it on our sequences...

ITS1f=CTTGGTCATTTAGAGGAAGTAA
degenITS1f=CTTGGT..TTT..A.G.A.TAA
ITS1fRC=TTACTTCCTCTAAATGACCAAG
ITS2=GCTGCGTTCTTCATCGATGC
ITS2RC=GCATCGATGAAGAACGCAGC

## now cycle through our demult files and get rid of these damn things...

cd /home/daniel/Documents/taiwan/taiwan_dada2/leaf_demult_fastx/R2_demult

for i in leafR2*
do
../../remove_runover.py -p $ITS2RC -f $i -o runover_removed/$i.1
echo $i.1
done

## check R1

grep $ITS1fRC * &

## check R2

grep $ITS1fRC * &

## seems clean. Fastx will tell us if the qscores line up... 

########## clip BOL primers, take 2 ##########

expr length 'CCACATCTATCTGCTGCGTTCTTCATCGATGC'

expr length 'CCCCATCATACCCTTGGTNATTTCGAGGCAGTAA'

cp leafR1_94.1 test.fastq
fastx_trimmer -i test.fastq -Q33 -f 33 -o BOLclippled/test.2.fastq
## seems okay

cd /home/daniel/Documents/taiwan/taiwan_dada2/leaf_demult_fastx/R1_demult/runover_removed

for i in leafR1*
do 
fastx_trimmer -i $i -f 33 -o BOLclippled/${i:: -1}2
echo BOLclippled/${i:: -1}2
done 


cd /home/daniel/Documents/taiwan/taiwan_dada2/leaf_demult_fastx/R2_demult/runover_removed

for i in leafR2*
do 
fastx_trimmer -i $i -f 35 -o BOLclippled/${i:: -1}2
echo BOLclippled/${i:: -1}2
done 

## did this work?

cd /home/daniel/Documents/taiwan/taiwan_dada2/leaf_demult_fastx/R1_demult/runover_removed/BOL*

sed -n '2p' <(head -n 20 R1_100) | grep $ITS2
sed -n '2p' <(head -n 20 R1_100clipped)

sed -n '2p' <(tail -n 4 R1_100) | grep $ITS2
sed -n '2p' <(tail -n 4 R1_100clipped)

## if this worked - remove the floating primers... another script?

## think so, cuz fastq

## god this is torturous. 

## so end game for tonight?

## get floating primer script ready - run it on wood reads, too?

## problem with the wood reads is that they remove the entire 
## read. How then do we maintain order in the files?

## hmm, think perhaps this is a step I should wait on - maybe I
## can slip it into the dada pipeline after merging paired ends?

## otherwise, that's another half day of banging my head on 
## python. 

## so what else? can it be that I'm ready for the dada2 pipeline?

## back up these demultiplexed, chopped sequences...

########### wood reads ####################

## look at wood reads - 
## do they have primers? RC primers? With runover?
## Are they uniform in size?
## have sample BPs been cleaned off?


## path to reads:

wooddir=/home/daniel/Documents/taiwan/woodreads

ITS1f=CTTGGTCATTTAGAGGAAGTAA
degenITS1f=CTTGGT..TTT..A.G.A.TAA
ITS1fRC=TTACTTCCTCTAAATGACCAAG
ITS2=GCTGCGTTCTTCATCGATGC
ITS2RC=GCATCGATGAAGAACGCAGC


## uniform in size?

sed -n '2p' <(head -n 10000 lane1-s254-index-GCATACAG-CCTAAGTCNNNN-133w_S254_L001_R2_001.fastq) | wc -c
sed -n '122p' <(head -n 10000 lane1-s254-index-GCATACAG-CCTAAGTCNNNN-133w_S254_L001_R2_001.fastq) | wc -c >> 
sed -n '1122p' <(head -n 10000 lane1-s254-index-GCATACAG-CCTAAGTCNNNN-133w_S254_L001_R2_001.fastq) | wc -c
sed -n '1122p' <(head -n 10000 lane1-s254-index-GCATACAG-CCTAAGTCNNNN-133w_S254_L001_R1_001.fastq) | wc -c
sed -n '1122p' <(head -n 10000 lane1-s195-index-CAACACCT-CCACTAAGNNNN-39w_S195_L001_R1_001.fastq) | wc -c
sed -n '1122p' <(tail -n 10000 lane1-s195-index-CAACACCT-CCACTAAGNNNN-39w_S195_L001_R1_001.fastq) | wc -c
sed -n '1122p' <(head -n 10000 lane1-s216-index-TCTCCGAT-AGCCGTAANNNN-72w_S216_L001_R1_001.fastq) | wc -c
sed -n '1122p' <(tail -n 10000 lane1-s216-index-TCTCCGAT-AGCCGTAANNNN-72w_S216_L001_R1_001.fastq) | wc -c
## seems like they're all 302 BP

wc -l lane1-s254-index-GCATACAG-CCTAAGTCNNNN-133w_S254_L001_R2_001.fastq ## 217548 / 4 = 54,387 reads

grep $ITS1fRC lane1-s254-index-GCATACAG-CCTAAGTCNNNN-133w_S254_L001_R2_001.fastq | wc -l
## 13,451 - not unimportant.

grep $ITS2 <(head -n 10000 lane1-s254-index-GCATACAG-CCTAAGTCNNNN-133w_S254_L001_R2_001.fastq)  | wc -l
grep $ITS2 <(head -n 10000 lane1-s254-index-GCATACAG-CCTAAGTCNNNN-133w_S254_L001_R2_001.fastq)  | wc -l

## so I guess we need to strip the reverse compliments and runover? 

## I don't hear anyone else talking about this...
## I wonder if it matters...

## hope it doesn't come back to shoot me in the foot. Oh well, here we go

#################

## are BOL primers and barcodes clean?

grep $ITS2 lane1-s254-index-GCATACAG-CCTAAGTCNNNN-133w_S254_L001_R2_001.fastq
grep $ITS1f lane1-s232-index-TCTCCGAT-ACGAATCCNNNN-94w_S232_L001_R1_001.fastq


grep $ITS2 <(head -n 10000 lane1-s254-index-GCATACAG-CCTAAGTCNNNN-133w_S254_L001_R2_001.fastq)

grep $ITS1f <(head -n 10000 lane1-s254-index-GCATACAG-CCTAAGTCNNNN-133w_S254_L001_R2_001.fastq)


grep -n $ITS1f lane1-s197-index-ACGACTTG-TGTTCCGTNNNN-45w_S197_L001_R1_001.fastq

grep -n $ITS1fRC lane1-s197-index-ACGACTTG-TGTTCCGTNNNN-45w_S197_L001_R2_001.fastq


## check some others:


grep $ITS1f lane1-s197-index-ACGACTTG-TGTTCCGTNNNN-45w_S197_L001_R1_001.fastq | wc -l

f=lane1-s240-index-TCTCCGAT-AATGGTCGNNNN-104w_S240_L001_R2_001.fastq
barcode=$(cut <(echo $f) -d "-" -f 4,5 | sed 's/-//' | sed 's/N*//g')

for i in *
do 
echo $i
barcode=$(cut <(echo $i) -d "-" -f 4,5 | sed 's/-//' | sed 's/N*//g')
echo $barcode found $(grep $barcode $i | wc -l) times
##grep $barcode $i | wc -l
done

## okay, so let's get rid of the runover BP and reverse compliments 
## on these wood reads:

dd=/home/daniel/Documents/taiwan/taiwan_dada2

cd /home/daniel/Documents/taiwan/woodreads/

for i in *R1*
do 
$dd/remove_runover.py -p $ITS2RC -f $i -o $dd/wood_runover_removed/$i
echo $i trimmed.
done

## for reverse reads, look for ITS1f reverse-compliment:
for i in *R2*
do 
$dd/remove_runover.py -p $ITS1fRC -f $i -o $dd/wood_runover_removed/$i
echo $i trimmed.
done







################################

## dada2 time ...
## use R... ugh...
## we need to deal with the libraries
## at a time, them combine them later
## with phyloseq

R

library(dada2)

packageVersion("dada2")

leafPath <- "/home/daniel/Documents/taiwan/taiwan_dada2/reads"

## maybe we should get these into the same directory?

list.files(leafPath)

getwd()

## get string of the forwards and reverse in the same order:

fnFs <- list.files(leafPath, pattern='R2', full.names=TRUE)

fnRs <- list.files(leafPath, pattern='R1', full.names=TRUE)

## check order 

head(fnFs, n=25)

head(fnRs, n=25)

tail(fnFs, n=25)

tail(fnRs, n=25)

## get a list of sample names

sample.names <- sapply(strsplit(basename(fnFs), '_'), '[', 2)
## that's cool. use the square bracket as a function,
## never done that before... a more elegant solution 
## to unrolling a list than I've come up with...
## but let's get rid of those ".2"s:
sample.names <- sub('\\.2', '', sample.names)


aa <- plotQualityProfile(fnFs[1])

plotQualityProfile(fnFs[1:10])

fnFs[seq(10,130,10)]

plotQualityProfile(fnFs[seq(10,130,10)])

##############################

## filtering

filt_path <- file.path(leafPath, "filtered")
filtFs <- file.path(filt_path, paste0(sample.names, "_F_filt.fastq"))
filtRs <- file.path(filt_path, paste0(sample.names, "_R_filt.fastq"))

out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(150,220),
                    maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE, multithread=FALSE)

## shit. the filter command isn't working. I think it doesn't like 
## our variable read lengths created by our removal of the RC primers 
## and downstream BP. 

## back up, just try it with BOL primers only clipped. 
## we can check for the RC primers after the pipeline, 
## along with the floating primers. 

#################################

## rebuild. Clip the demultiplexed fastqs:

## for R1 reads, first bp is 33

cd /home/daniel/Documents/taiwan/taiwan_dada2/reads

for i in leafR1*
do
fastx_trimmer -i $i -f 33 -o dmult_BOLclipped/$i.fastq
echo dmult_BOLclipped/$i.fastq
done

## and as a script, " R2clip.sh

for i in leafR2*
do
fastx_trimmer -i $i -f 35 -o dmult_BOLclipped/$i.fastq
echo dmult_BOLclipped/$i.fastq
done

at -f ./R2clip.sh -mv now + 45 minutes



## wood reads... pretty much don't need to do anything, 
## BOL primers already gone, and we're not getting 
## rid of the others. 

## rerun merge with these just-BOL-clipped reads, 
## see if we get the same error,

## if not, clean up the notebook and git 
## and go to bed


#############################

## worked. so look at this:

library(dada2)

load("leafForwardFilterAndTrim.rda")

aa <- c('zzop','mmop','ppop','hhop','wwop','ggop')
bb <- c(5,2,9,4,1,6)
cc <- c('z','m','p','h','w','g')
dd <- data.frame(aa,bb,cc)

dd[order(bb, decreasing=FALSE),]

ee <- out[order(out[,1], decreasing=TRUE),]

barplot(t(ee[1:50,]), 
    beside=TRUE, 
    col=c("blue","yellow"), 
    axes=FALSE,
    axisnames=FALSE,
    xlab='samples',
    ylab='read #',
    )
axis(2)
legend(x="top", legend=c('before','after'), fill=c('blue','yellow'))

barplot(t(ee), 
    beside=TRUE, 
    col=c("blue","yellow"), 
    axes=FALSE,
    axisnames=FALSE,
    xlab='samples',
    ylab='read #',
    )
axis(2)
legend(x="top", legend=c('before','after'), fill=c('blue','yellow'))

tout <- t(out[order(out[,1], decreasing=TRUE),])

barplot(tout, 
    beside=TRUE, 
    col=c("blue","yellow"), 
    axes=FALSE,
    axisnames=FALSE,
    xlab='samples',
    ylab='read #',
    )
axis(2)
legend(x="top", legend=c('before','after'), fill=c('blue','yellow'))
## filtered reads at 

filtered=/home/daniel/Documents/taiwan/taiwan_dada2/reads/dmult_BOLclipped/filtered

## we want to do our dereplicating on the desktop. Can we set that up?

## need our filtered files, etc. Script looks like:

library('dada2')
setwd('/home/daniel/Documents/submissions/taibioinfo/taiwan_dada2')
load('sample.names.rda')
filt_path <- "/home/daniel/Documents/submissions/taibioinfo/dada2_notgit/filtered"
filtFs <- file.path(filt_path, paste0(sample.names, "_F_filt.fastq"))
filtRs <- file.path(filt_path, paste0(sample.names, "_R_filt.fastq"))
derepFs <- derepFastq(filtFs, verbose=TRUE)
derepRs <- derepFastq(filtRs, verbose=TRUE)
names(derepFs) <- sample.names
names(derepRs) <- sample.names
save(derepFs, file='derepFs.rda')
save(derepRs, file='derepRs.rda')

## psid 9385

## seems to be working. let that sit...

## looks like the extra memory helped.... get those files onto laptop

## we want to do something similar for the merging. The script on
## the optiplex will look something like:


library('dada2')

load('dadaFs.rda')
load('dadaRs.rda')
load('derepFs.rda')
load('derepRs.rda')

mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE)

save(mergers, file='mergers.rda')


###########

(R CMD BATCH mergeends.R &) &
## pid 9708
## let that run, let's  go to sleep.
## at some point, we need to clean up for git. 

load('mergers.rda')

seqtab <- makeSequenceTable(mergers)

aa <- table(nchar(getSequences(seqtab)))

barplot(aa)


##############################

## taxonomy

## back to this can of worms. Unless things have changed
## I think we need to get the newest UNITE database,
## remove reads without classifications to at least 
## class level. 

## but dada2 trains its algorithms on a a "Training" set 
## of reads... is this available for UNITE and will this 
## cause problems?

I think I understand to that UNITE provides two versionsof it's database. One, with ~58,000 sequences, I think has all sequences that have been successfully submitted to the database. Then there is a smaller fasta file with~ ~31,000 sequences, which has been trimmed to clustered"Species hypothesis", some 9000 of which have been vetted by experts in a taxonomic group (also in the larger. Singletons that are clustered to a SH elsewhereare discarded, I think. so which do we use? Let's stay with the more curated version...
UNITE='/home/daniel/Documents/taiwan/UNITE/sh_general_release_dynamic_01.12.2017.fasta'

## what does this look like?

head -n 1 $UNITE

## I think this needs to be changed so dada2 can parse 
## it. Also, is there a way to check to see if many 
## of these are missing class or lower classification?


head -n 1000 $UNITE | less

grep "c__unidentified" $UNITE | wc -l ## 1033

grep "c__unidentified" $UNITE | grep "p__unidentified" | wc -l ## 601

## if it is missing class id, it is missing genus 
grep "c__unidentified" $UNITE | grep -v "g__unidentified" | wc -l ## 0
grep "c__unidentified" $UNITE | grep "g__unidentified" | wc -l ## 1033

## are these what we need to remove? 
## seems simple... python time?

## nah, fuggit. It's got a training algorithm, hopefully this means 
## it can make tax assignments without needing a high match to one 
## of the sequences in the DB. 

## and the parsing might work as is. So before we launch a crusade, 
## let's see if the out-of-box commands work


## and oops too heavy for my computer....

## can we farm this out to the desktop?

## r script:


#########################
## leaftaxation.R

library(dada2)

load('dadaFs.rda')
load('leafFilterAndTrim.rda')
load('sample.names.rda')
load('mergers.rda')
load('seqtab.nochim.rda')

taxa <- assignTaxonomy(seqtab.nochim, "sh_general_release_dynamic_01.12.2017.fasta" , multithread=TRUE)

save(taxa, file='taxa.rda')

#############################

## scp this and the UNITE files  over to the desktop,
## and let the old beast chew on it for a while

R CMD BATCH leaftaxation.R

## okay, what does this look like?

R 
library(dada2)
load('leafFilterAndTrim.rda')
load('sample.names.rda')
load('mergers.rda')
load('seqtab.nochim.rda')


load('taxa.rda')

str(taxa)

taxa[[2]]

head(taxa, n=1)


## okay, so 7777 sequences, these are our ASVs?
## then a tax table. 

## how many of our ASVs were identified to species?

rownames(taxa) ## our ASV sequences are our rownames

colnames(taxa) ## taxonomic levels for colnames

taxa[1,]

bb = is.na(taxa)

colSums(bb)/ nrow(bb)

colSums(taxa)

head(taxa[,"Phylum"])

aa <- taxa[,"Phylum"]

load('dadaFs.rda')
load('dadaRs.rda')

class(dadaFs)

length(dadaFs)

dadaFs[[1]]

class(dadaFs[[2]])

length(dadaFs[[2]])

str(dadaFs[[2]][1])

dadaFs[[2]][1]


############### wood reads into dada2 pipe #########################

## okay, run the wood reads through

R 

library('dada2')

wooddir <- '/home/daniel/Documents/taiwan/woodreads'

## get the forwards (R1):

fnFs <- list.files(wooddir, pattern="_R1_001.fastq", full.names = TRUE)
fnRs <- list.files(wooddir, pattern="_R2_001.fastq", full.names = TRUE)

## we want to get a string of sample names from our files names:

get_sampname <- function(stri){
    bb <- strsplit(stri, "NNNN-")[[1]][2]
    cc <- strsplit(bb, "_")[[1]][1]
    return(cc) }


wood.sample.names <- unname(sapply(fnFs, get_sampname))


